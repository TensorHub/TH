# DeepSeek-OCR: Contexts Optical Compression

# Содержание

- [Введение](#введение)
- [Контекст проблемы и мотивация](#контекст-проблемы-и-мотивация)
- [Архитектура и технический подход](#архитектура-и-технический-подход)
- [Анализ производительности сжатия](#анализ-производительности-сжатия)
- [Практические применения и возможности](#практические-применения-и-возможности)
- [Результаты оценки](#результаты-оценки)
- [Будущие последствия и механизмы памяти](#будущие-последствия-и-механизмы-памяти)
- [Значение и вклад](#значение-и-вклад)
- [Соответствующие цитаты](#соответствующие-цитаты)

---

## Введение

DeepSeek-OCR представляет собой систематическое исследование "оптической компрессии контекстов" — парадигмы, которая использует визуальную модальность как эффективный механизм сжатия текстовой информации в больших языковых моделях (LLM). В то время как LLM сталкиваются со значительными вычислительными проблемами при работе с длинными контекстами из-за квадратичного масштабирования, эта работа демонстрирует, что документы, представленные в виде изображений, могут достигать существенных коэффициентов сжатия при сохранении высокой точности OCR, потенциально решая фундаментальные ограничения масштабируемости в современных системах ИИ.

<figure>
  <img src="https://raw.githubusercontent.com/TensorHub/TH/refs/heads/main/research/0001-DeepSeek-OCR/review/diagrams/Drawing-01.jpeg " alt="Рисунок 1">
  <figcaption>Рисунок 1: (а) DeepSeek-OCR достигает 97% точности при коэффициентах сжатия ~10x на бенчмарке Fox, демонстрируя эффективную компрессию визия-текста. (б) Модель достигает современного уровня производительности на OmniDocBench, используя значительно меньше визуальных токенов, чем конкурирующие подходы.</figcaption>
</figure>

## Контекст проблемы и мотивация

Текущие визуально-языковые модели (VLM) испытывают трудности с эффективной обработкой текстовых документов. Существующие подходы имеют свои ограничения:

<figure>
  <img src="https://raw.githubusercontent.com/TensorHub/TH/refs/heads/main/research/0001-DeepSeek-OCR/review/diagrams/Drawing-02.jpeg " alt="Рисунок 2">
  <figcaption>Рисунок 2: Ограничения текущих подходов VLM, включая требования к двойной предварительной обработке, чрезмерное количество токенов и ограничения памяти, которые DeepSeek-OCR решает с помощью своей унифицированной архитектуры.</figcaption>
</figure>

Двухбашенные архитектуры, такие как Vary, требуют сложной двойной предварительной обработки изображений, что усложняет развертывание. Методы на основе тайлов, такие как InternVL2.0, страдают от низкого нативного разрешения кодировщика, что приводит к чрезмерной фрагментации для больших изображений. Подходы адаптивного разрешения кодирования, такие как Qwen2-VL, сталкиваются с огромным потреблением памяти активаций, что может вызвать переполнение GPU.

Основное новшество DeepSeek-OCR заключается в переосмыслении OCR как задачи сжатия-распаковки. Вместо простого преобразования визуального текста в цифровой формат, система рассматривает изображения как сжатые представления текстовой информации, позволяя LLM обрабатывать обширные документы со значительно сниженными вычислительными затратами.

## Архитектура и технический подход

...

## Анализ производительности сжатия

...

## Практические применения и возможности

...

## Результаты оценки

...

## Будущие последствия и механизмы памяти

...

## Значение и вклад

...

## Соответствующие цитаты

...