# DeepSeek-OCR: Contexts Optical Compression

# Содержание

- [Введение](#введение)
- [Контекст проблемы и мотивация](#контекст-проблемы-и-мотивация)
- [Архитектура и технический подход](#архитектура-и-технический-подход)
- [Анализ производительности сжатия](#анализ-производительности-сжатия)
- [Практические применения и возможности](#практические-применения-и-возможности)
- [Результаты оценки](#результаты-оценки)
- [Будущие последствия и механизмы памяти](#будущие-последствия-и-механизмы-памяти)
- [Значение и вклад](#значение-и-вклад)
- [Соответствующие цитаты](#соответствующие-цитаты)

---

## Введение

DeepSeek-OCR представляет собой систематическое исследование "оптической компрессии контекстов" — парадигмы, которая использует визуальную модальность как эффективный механизм сжатия текстовой информации в больших языковых моделях (LLM). В то время как LLM сталкиваются со значительными вычислительными проблемами при работе с длинными контекстами из-за квадратичного масштабирования, эта работа демонстрирует, что документы, представленные в виде изображений, могут достигать существенных коэффициентов сжатия при сохранении высокой точности OCR, потенциально решая фундаментальные ограничения масштабируемости в современных системах ИИ.

<figure>
  <img src="https://raw.githubusercontent.com/TensorHub/TH/refs/heads/main/research/0001-DeepSeek-OCR/review/diagrams/Drawing-01.jpeg " alt="Рисунок 1">
  <figcaption>Рисунок 1: (а) DeepSeek-OCR достигает 97% точности при коэффициентах сжатия ~10x на бенчмарке Fox, демонстрируя эффективную компрессию визия-текста. (б) Модель достигает современного уровня производительности на OmniDocBench, используя значительно меньше визуальных токенов, чем конкурирующие подходы.</figcaption>
</figure>

## Контекст проблемы и мотивация

Текущие визуально-языковые модели (VLM) испытывают трудности с эффективной обработкой текстовых документов. Существующие подходы имеют свои ограничения:

<figure>
  <img src="https://raw.githubusercontent.com/TensorHub/TH/refs/heads/main/research/0001-DeepSeek-OCR/review/diagrams/Drawing-02.jpeg " alt="Рисунок 2">
  <figcaption>Рисунок 2: Ограничения текущих подходов VLM, включая требования к двойной предварительной обработке, чрезмерное количество токенов и ограничения памяти, которые DeepSeek-OCR решает с помощью своей унифицированной архитектуры.</figcaption>
</figure>


<html lang="ru">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Проблемы современных VLM и подход DeepSeek-OCR</title>
  <style>
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif;
      line-height: 1.6;
      color: #24292e;
      max-width: 800px;
      margin: 40px auto;
      padding: 0 20px;
      background-color: #ffffff;
    }
    h1 {
      font-size: 28px;
      font-weight: 600;
      margin-bottom: 24px;
      border-bottom: 1px solid #eaecef;
      padding-bottom: 8px;
    }
    h2 {
      font-size: 22px;
      font-weight: 600;
      margin-top: 32px;
      margin-bottom: 16px;
    }
    ul {
      padding-left: 24px;
      margin-bottom: 24px;
    }
    li {
      margin-bottom: 10px;
    }
    .highlight {
      background-color: #f6f8fa;
      padding: 16px;
      border-left: 4px solid #0969da;
      border-radius: 6px;
      margin-top: 24px;
    }
    .model-name {
      font-weight: 600;
      color: #0969da;
    }
  </style>
</head>
<body>

  <h1>Проблемы современных Vision-Language Models (VLM) и инновация DeepSeek-OCR</h1>

  <h2>Основные проблемы текущих подходов:</h2>
  <ul>
    <li>
      <span class="model-name">Двухбашенные архитектуры (например, Vary)</span> требуют сложной двойной предварительной обработки изображений — отдельно для визуальных и текстовых компонентов. Это усложняет развертывание и увеличивает вычислительные накладные расходы.
    </li>
    <li>
      <span class="model-name">Методы на основе тайлов (например, InternVL2.0)</span> используют низкое нативное разрешение визуального кодировщика, что приводит к чрезмерной фрагментации больших изображений и снижает целостность восприятия текста.
    </li>
    <li>
      <span class="model-name">Подходы с адаптивным разрешением (например, Qwen2-VL)</span> генерируют огромное количество активаций, вызывая высокое потребление видеопамяти и риск переполнения GPU при обработке крупных документов.
    </li>
  </ul>

  <div class="highlight">
    <h2>Ключевая инновация DeepSeek-OCR</h2>
    <p>
      DeepSeek-OCR переосмысливает оптическое распознавание символов (OCR) как задачу <strong>сжатия–распаковки</strong>. 
      Вместо прямого преобразования изображений в текст, система рассматривает визуальные документы как <em>сжатые представления текстовой информации</em>. 
      Это позволяет языковой модели (LLM) эффективно обрабатывать объёмные документы с <strong>минимальными вычислительными и памятными затратами</strong>, 
      обеспечивая при этом высокую точность и масштабируемость в рамках унифицированной архитектуры.
    </p>
  </div>

</body>
</html>

## Архитектура и технический подход

...

## Анализ производительности сжатия

...

## Практические применения и возможности

...

## Результаты оценки

...

## Будущие последствия и механизмы памяти

...

## Значение и вклад

...

## Соответствующие цитаты

...