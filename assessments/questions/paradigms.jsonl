{"id":"paradigms-0001","axis":"Paradigms","subdomain":"Supervised Learning","difficulty":1,"type":"mcq","prompt":"Что такое обучение с учителем (supervised learning)?","options":["Обучение без метки целевой переменной","Обучение на размеченных примерах с известными ответами","Учение от другого человека","Использование разных моделей"],"answer":1,"explanation":"Supervised Learning: модель учится на парах (X, y), где y — истинный ответ."}
{"id":"paradigms-0002","axis":"Paradigms","subdomain":"Unsupervised Learning","difficulty":1,"type":"truefalse","prompt":"В обучении без учителя все примеры имеют целевую переменную y.","answer":false,"explanation":"Unsupervised Learning работает только с входными данными X, без меток y."}
{"id":"paradigms-0003","axis":"Paradigms","subdomain":"Supervised Learning","difficulty":2,"type":"mcq","prompt":"Какие основные парадигмы машинного обучения?","options":["Только supervised","Supervised, unsupervised, reinforcement и semi-supervised","Только unsupervised","Только reinforcement"],"answer":1,"explanation":"Четыре основные парадигмы: supervised, unsupervised, reinforcement, semi-supervised."}
{"id":"paradigms-0004","axis":"Paradigms","subdomain":"Reinforcement Learning","difficulty":2,"type":"short","prompt":"Как называется агент, который получает награды и штрафы за действия в окружении?","answer":"reinforcement learning agent","explanation":"RL agent учится максимизировать кумулятивную награду через взаимодействие с окружением."}
{"id":"paradigms-0005","axis":"Paradigms","subdomain":"Semi-supervised Learning","difficulty":2,"type":"mcq","prompt":"Что такое полу-контролируемое обучение (semi-supervised)?","options":["Только на размеченных данных","Обучение на смеси размеченных и неразмеченных данных","Обучение без данных","Рекомендационные системы"],"answer":1,"explanation":"Semi-supervised Learning: используются оба типа данных для улучшения обобщения."}
{"id":"paradigms-0006","axis":"Paradigms","subdomain":"Unsupervised Learning","difficulty":3,"type":"mcq","prompt":"Какая задача относится к unsupervised learning?","options":["Классификация текста","Кластеризация документов","Предсказание цены акции","Диагностика болезни"],"answer":1,"explanation":"Кластеризация находит группы в данных без известных меток (unsupervised)."}
{"id":"paradigms-0007","axis":"Paradigms","subdomain":"Self-Supervised Learning","difficulty":3,"type":"short","prompt":"Как называется парадигма, где модель предсказывает части данных из других частей?","answer":"self-supervised learning","explanation":"Self-supervised learning: модель создаёт собственные метки из структуры данных (например, маскирование слов)."}
{"id":"paradigms-0008","axis":"Paradigms","subdomain":"Reinforcement Learning","difficulty":3,"type":"mcq","prompt":"Что такое MDP (Markov Decision Process)?","options":["Много точек данных","Математическая модель для RL с состояниями, действиями и наградами","Метрика оценивания","Функция потерь"],"answer":1,"explanation":"MDP: S (states), A (actions), R (rewards), P (transitions) — формализм RL."}
{"id":"paradigms-0009","axis":"Paradigms","subdomain":"Transfer Learning","difficulty":3,"type":"truefalse","prompt":"Transfer Learning переносит знания из одной задачи в другую задачу.","answer":true,"explanation":"Transfer Learning использует предварительно обученную модель для новой задачи с меньшими данными."}
{"id":"paradigms-0010","axis":"Paradigms","subdomain":"Supervised Learning","difficulty":3,"type":"mcq","prompt":"Какая проблема может возникнуть при supervised learning на несбалансированных данных?","options":["Модель работает слишком быстро","Модель может переобучиться на большинство класса","Нет проблемы","Градиент исчезает"],"answer":1,"explanation":"Class imbalance: модель смещена в сторону большинства класса; нужны специальные методы."}
{"id":"paradigms-0011","axis":"Paradigms","subdomain":"Meta-Learning","difficulty":3,"type":"short","prompt":"Как называется парадигма обучения, которая учится учиться (learning to learn)?","answer":"meta-learning","explanation":"Meta-learning: модель учится оптимально настраиваться на новые задачи с небольшим количеством примеров."}
{"id":"paradigms-0012","axis":"Paradigms","subdomain":"Federated Learning","difficulty":4,"type":"mcq","prompt":"Что такое federated learning?","options":["Обучение на централизованном сервере","Распределённое обучение на множестве устройств без передачи сырых данных","Обучение с подкреплением","Кластеризация"],"answer":1,"explanation":"Federated Learning: модель обучается на локальных устройствах; обновления отправляются на сервер (приватность)."}
{"id":"paradigms-0013","axis":"Paradigms","subdomain":"Reinforcement Learning","difficulty":4,"type":"truefalse","prompt":"Q-learning — это off-policy алгоритм, который не требует знания оптимальной политики.","answer":true,"explanation":"Q-learning учится оптимальной политики, исследуя окружение (off-policy)."}
{"id":"paradigms-0014","axis":"Paradigms","subdomain":"Self-Supervised Learning","difficulty":4,"type":"mcq","prompt":"Какой метод self-supervised learning используется в BERT?","options":["Маскирование случайных слов в предложении","Классификация изображений","Регрессия цены","Кластеризация"],"answer":0,"explanation":"BERT использует masked language modeling: предсказывает замаскированные слова из контекста."}
{"id":"paradigms-0015","axis":"Paradigms","subdomain":"Active Learning","difficulty":4,"type":"short","prompt":"Как называется парадигма, где модель выбирает, какие примеры разметить?","answer":"active learning","explanation":"Active Learning: модель запрашивает разметку для наиболее информативных примеров."}
{"id":"paradigms-0016","axis":"Paradigms","subdomain":"Transfer Learning","difficulty":4,"type":"mcq","prompt":"Какой подход лучше при малом количестве данных для целевой задачи?","options":["Обучить модель с нуля","Fine-tune предварительно обученную модель","Использовать только правила","Увеличить размер модели"],"answer":1,"explanation":"Transfer Learning эффективнее: используем features из большого датасета и адаптируем на малый."}
{"id":"paradigms-0017","axis":"Paradigms","subdomain":"Contrastive Learning","difficulty":5,"type":"mcq","prompt":"Что такое contrastive learning?","options":["Обучение противоположным примерам","Обучение, максимизирующее сходство похожих примеров и различие непохожих","Усиление контраста в изображениях","Параллельное обучение"],"answer":1,"explanation":"Contrastive Learning: модель учится embedding'ам, где похожие примеры близко, непохожие — далеко."}
{"id":"paradigms-0018","axis":"Paradigms","subdomain":"Curriculum Learning","difficulty":5,"type":"truefalse","prompt":"Curriculum Learning начинает с простых примеров и постепенно усложняет задачу.","answer":true,"explanation":"Curriculum Learning улучшает сходимость и финальную производительность, как обучение человека."}
{"id":"paradigms-0019","axis":"Paradigms","subdomain":"Zero-shot Learning","difficulty":5,"type":"short","prompt":"Как называется задача предсказания на классах, которых модель никогда не видела?","answer":"zero-shot learning","explanation":"Zero-shot Learning: модель обобщает на невидимые классы через описания или атрибуты."}
{"id":"paradigms-0020","axis":"Paradigms","subdomain":"Continual Learning","difficulty":5,"type":"mcq","prompt":"Что такое catastrophic forgetting в continual learning?","options":["Забывание кода","Потеря производительности на старых задачах при обучении на новых","Вычислительные ошибки","Проблема с памятью GPU"],"answer":1,"explanation":"Catastrophic Forgetting: нейросеть забывает старые знания при обучении на новых данных."}
